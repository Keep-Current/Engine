{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP-based Recommenders\n",
    "\n",
    "Compare models for NLP-based recommender of Engine\n",
    "\n",
    "(Refactored from `Computing Similarity using Latent Semantic Analysis on a personal corpus` NB by Liad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to nltk/...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os, re, glob, ujson, urllib.request\n",
    "from pathlib import Path\n",
    "\n",
    "import nltk\n",
    "nltk.download(\"punkt\", download_dir=\"nltk/\")\n",
    "nltk.data.path.append(\"nltk/\")\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from gensim.corpora import Dictionary, MmCorpus\n",
    "from gensim import models, utils, similarities\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "Using papers from `Reasoning Corpus/` directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/Reasoning_Corpus/Aspect-augmented Adversarial Networks for Domain Adaptation.txt\n",
      "data/Reasoning_Corpus/Rationalizing Neural Predictions.txt\n",
      "data/Reasoning_Corpus/Explaining the Predictions of Any Classifier.txt\n",
      "data/Reasoning_Corpus/Representation Learning for Grounded Spatial Reasoning.txt\n"
     ]
    }
   ],
   "source": [
    "class Corpus(object):\n",
    "    \"\"\"\n",
    "    Memory efficient represantation of corpus\n",
    "    \"\"\"\n",
    "    def __iter__(self):\n",
    "        for file in glob.glob(\"data/Reasoning_Corpus/*.txt\"):\n",
    "            print(file)\n",
    "            paper = Path(file).read_text(encoding=\"utf8\")\n",
    "            yield paper\n",
    "    \n",
    "    @property\n",
    "    def titles(self): # TBD\n",
    "        titles = []\n",
    "        for file in glob.glob(\"data/Reasoning_Corpus/*.txt\"):\n",
    "            f_name = os.path.split(file)[-1]\n",
    "            title = os.path.splitext(f_name)[0]\n",
    "            titles.append(title)\n",
    "        return titles\n",
    "            \n",
    "corpus_memory_friendly = Corpus()\n",
    "papers = list(corpus_memory_friendly)\n",
    "papers_titles = corpus_memory_friendly.titles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPECIAL_CHARS = \"[^A-Za-z0-9 ]+\" # TBD\n",
    "stopword_list = stopwords.words(\"english\")\n",
    "stopword_list.extend([\"et\", \"al\"])\n",
    "\n",
    "def tokenize(text):\n",
    "    \"\"\"\n",
    "    Tokenize input text\n",
    "    :param text: Text sequence\n",
    "    :return: [tokens]\n",
    "    \"\"\"\n",
    "    tokens = [re.sub(SPECIAL_CHARS, \"\", word.lower()) for word in nltk.word_tokenize(text)] # remove special chars\n",
    "    tokens = [re.sub(r\"^arxiv.*\", \"\", token) for token in tokens] # remove arxiv refs\n",
    "    tokens = [re.sub(r\"\\b[0-9][0-9.,-]*\\b\", \"UNIFIED-NUMBER-TOKEN\", token) for token in tokens] # replace numbers with special token; TBD: Add yk, yth, yx etc\n",
    "    tokens = [word for word in tokens if word not in stopword_list]\n",
    "    tokens = list(filter(None, tokens))\n",
    "    \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4059"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_iterator = [list(tokenize(paper)) for paper in papers]\n",
    "\n",
    "dictionary = Dictionary(doc_iterator) # gensim.corpora.Dictionary\n",
    "len(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See Dict\n",
    "#dictionary.token2id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BoW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [dictionary.doc2bow(doc) for doc in doc_iterator]\n",
    "MmCorpus.serialize(\"data/training/reasoning_corpus.mm\", corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = models.TfidfModel(corpus)\n",
    "tfidf_corpus = tfidf[corpus]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Latent Semantic Indexing](https://nlp.stanford.edu/IR-book/html/htmledition/latent-semantic-indexing-1.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.915*\"UNIFIED-NUMBER-TOKEN\" + 0.147*\"model\" + 0.091*\"x\" + 0.078*\"learning\" + 0.060*\"explanations\" + 0.058*\"classifier\" + 0.057*\"dataset\" + 0.054*\"training\" + 0.052*\"set\" + 0.052*\"figure\"'),\n",
       " (1,\n",
       "  '0.332*\"explanations\" + 0.177*\"predictions\" + -0.175*\"domain\" + 0.165*\"features\" + 0.162*\"lime\" + -0.159*\"aspect\" + 0.151*\"trust\" + 0.150*\"explanation\" + 0.141*\"interpretable\" + 0.136*\"users\"'),\n",
       " (2,\n",
       "  '0.254*\"instructions\" + 0.209*\"goal\" + -0.206*\"domain\" + -0.177*\"classifier\" + 0.165*\"value\" + 0.163*\"language\" + 0.147*\"map\" + 0.144*\"global\" + 0.139*\"spatial\" + 0.136*\"instruction\"'),\n",
       " (3,\n",
       "  '0.263*\"rationales\" + 0.217*\"rationale\" + 0.189*\"generator\" + -0.170*\"instructions\" + 0.167*\"z\" + 0.167*\"encoder\" + 0.165*\"neural\" + -0.137*\"model\" + -0.137*\"goal\" + 0.127*\"recurrent\"')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsi_bow = models.LsiModel(corpus, id2word=dictionary, num_topics=20)\n",
    "lsi_bow.show_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.246*\"rationale\" + 0.215*\"generator\" + 0.208*\"explanations\" + 0.200*\"lime\" + 0.156*\"rationales\" + 0.155*\"instructions\" + 0.154*\"z\" + 0.154*\"adversarial\" + 0.150*\"relevance\" + 0.131*\"pathology\"'),\n",
       " (1,\n",
       "  '0.512*\"instructions\" + 0.274*\"instruction\" + 0.256*\"policy\" + 0.247*\"environment\" + 0.155*\"global\" + 0.137*\"uvfa\" + 0.110*\"locations\" + 0.110*\"environments\" + 0.110*\"agent\" + -0.105*\"adversarial\"'),\n",
       " (2,\n",
       "  '0.256*\"adversarial\" + 0.250*\"relevance\" + -0.249*\"explanations\" + -0.243*\"lime\" + 0.218*\"pathology\" + 0.205*\"transfer\" + 0.131*\"source\" + -0.117*\"interpretable\" + 0.116*\"document\" + -0.114*\"explanation\"'),\n",
       " (3,\n",
       "  '0.330*\"rationale\" + 0.288*\"generator\" + -0.223*\"explanations\" + -0.222*\"lime\" + 0.200*\"rationales\" + 0.144*\"gen\" + 0.127*\"zx\" + 0.126*\"encoder\" + -0.122*\"adversarial\" + -0.119*\"relevance\"')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsi_tfidf = models.LsiModel(tfidf_corpus, id2word=dictionary, num_topics=10)\n",
    "lsi_tfidf.show_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Latent Dirichlet Allocation](https://en.wikipedia.org/wiki/Latent_Dirichlet_allocation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.065*\"UNIFIED-NUMBER-TOKEN\" + 0.011*\"model\" + 0.007*\"x\" + 0.005*\"learning\" + 0.005*\"explanations\" + 0.004*\"classifier\" + 0.004*\"set\" + 0.004*\"dataset\" + 0.004*\"figure\" + 0.004*\"use\"'),\n",
       " (1,\n",
       "  '0.045*\"UNIFIED-NUMBER-TOKEN\" + 0.011*\"model\" + 0.006*\"x\" + 0.005*\"learning\" + 0.004*\"explanations\" + 0.004*\"classifier\" + 0.004*\"figure\" + 0.003*\"use\" + 0.003*\"dataset\" + 0.003*\"set\"'),\n",
       " (2,\n",
       "  '0.058*\"UNIFIED-NUMBER-TOKEN\" + 0.010*\"model\" + 0.006*\"learning\" + 0.006*\"domain\" + 0.005*\"x\" + 0.005*\"classifier\" + 0.005*\"dataset\" + 0.004*\"set\" + 0.004*\"explanations\" + 0.004*\"training\"'),\n",
       " (3,\n",
       "  '0.039*\"UNIFIED-NUMBER-TOKEN\" + 0.007*\"model\" + 0.005*\"x\" + 0.004*\"learning\" + 0.003*\"instructions\" + 0.003*\"figure\" + 0.003*\"set\" + 0.003*\"use\" + 0.003*\"using\" + 0.003*\"goal\"'),\n",
       " (4,\n",
       "  '0.059*\"UNIFIED-NUMBER-TOKEN\" + 0.010*\"model\" + 0.007*\"learning\" + 0.005*\"x\" + 0.004*\"models\" + 0.004*\"training\" + 0.004*\"figure\" + 0.004*\"classifier\" + 0.004*\"dataset\" + 0.004*\"explanations\"'),\n",
       " (5,\n",
       "  '0.063*\"UNIFIED-NUMBER-TOKEN\" + 0.009*\"model\" + 0.007*\"x\" + 0.005*\"explanations\" + 0.005*\"learning\" + 0.004*\"task\" + 0.004*\"dataset\" + 0.004*\"set\" + 0.004*\"figure\" + 0.004*\"text\"'),\n",
       " (6,\n",
       "  '0.072*\"UNIFIED-NUMBER-TOKEN\" + 0.010*\"model\" + 0.009*\"x\" + 0.005*\"training\" + 0.005*\"aspect\" + 0.004*\"learning\" + 0.004*\"use\" + 0.004*\"target\" + 0.004*\"domain\" + 0.004*\"prediction\"'),\n",
       " (7,\n",
       "  '0.033*\"UNIFIED-NUMBER-TOKEN\" + 0.008*\"model\" + 0.006*\"x\" + 0.005*\"explanations\" + 0.004*\"figure\" + 0.004*\"neural\" + 0.004*\"learning\" + 0.004*\"rationales\" + 0.003*\"text\" + 0.003*\"training\"'),\n",
       " (8,\n",
       "  '0.079*\"UNIFIED-NUMBER-TOKEN\" + 0.013*\"model\" + 0.008*\"x\" + 0.005*\"dataset\" + 0.005*\"learning\" + 0.005*\"figure\" + 0.004*\"set\" + 0.004*\"explanations\" + 0.004*\"neural\" + 0.004*\"use\"'),\n",
       " (9,\n",
       "  '0.078*\"UNIFIED-NUMBER-TOKEN\" + 0.013*\"model\" + 0.008*\"learning\" + 0.007*\"x\" + 0.005*\"two\" + 0.005*\"training\" + 0.004*\"dataset\" + 0.004*\"instructions\" + 0.004*\"set\" + 0.004*\"classifier\"')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_bow = models.LdaMulticore(corpus, id2word=dictionary, num_topics=10) # sounds faster than models.LdaModel ;)\n",
    "lda_bow.show_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommenders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fetch documents from Crawler microservice. Acutally limited to 100 most recent papers. #TODO change to fetch DB when MongoDB is set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'publish_date': '2018-06-21T17:59:09Z',\n",
       "  'authors': ['Deepak Pathak',\n",
       "   'Yide Shentu',\n",
       "   'Dian Chen',\n",
       "   'Pulkit Agrawal',\n",
       "   'Trevor Darrell',\n",
       "   'Sergey Levine',\n",
       "   'Jitendra Malik'],\n",
       "  'title': 'Learning Instance Segmentation by Interaction',\n",
       "  'abstract': \"We present an approach for building an active agent that learns to segment\\nits visual observations into individual objects by interacting with its\\nenvironment in a completely self-supervised manner. The agent uses its current\\nsegmentation model to infer pixels that constitute objects and refines the\\nsegmentation model by interacting with these pixels. The model learned from\\nover 50K interactions generalizes to novel objects and backgrounds. To deal\\nwith noisy training signal for segmenting objects obtained by self-supervised\\ninteractions, we propose robust set loss. A dataset of robot's interactions\\nalong-with a few human labeled examples is provided as a benchmark for future\\nresearch. We test the utility of the learned segmentation model by providing\\nresults on a downstream vision-based control task of rearranging multiple\\nobjects into target configurations from visual inputs alone. Videos, code, and\\nrobotic interaction dataset are available at\\nhttps://pathak22.github.io/seg-by-interaction/\",\n",
       "  'id': 'http://arxiv.org/abs/1806.08354v1',\n",
       "  'link': 'http://arxiv.org/abs/1806.08354v1',\n",
       "  'pdf': 'http://arxiv.org/pdf/1806.08354v1',\n",
       "  '_rawid': '1806.08354',\n",
       "  '_version': 1}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with urllib.request.urlopen('https://keepcurrent-crawler.herokuapp.com/arxiv') as url:\n",
    "            response = url.read()\n",
    "        \n",
    "crawled_docs = ujson.loads(response)\n",
    "crawled_docs[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TBD: Uses abstracts only. #TODO change to parsed document, when pdf extraction is ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "abstracts = [doc[\"abstract\"] for doc in crawled_docs]\n",
    "titles = [doc[\"title\"] for doc in crawled_docs]\n",
    "authors = [doc[\"authors\"] for doc in crawled_docs]\n",
    "links = [doc[\"link\"] for doc in crawled_docs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess abstracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "abstract_tokens = [tokenize(abstract) for abstract in abstracts]\n",
    "abstract_tokens_bow = [dictionary.doc2bow(abstract) for abstract in abstract_tokens]\n",
    "abstract_tokens_tfidf = tfidf[abstract_tokens_bow]\n",
    "\n",
    "vec_lsi_bow = [lsi_bow[bow_vector] for bow_vector in abstract_tokens_bow]\n",
    "vec_lsi_tfidf = [lsi_tfidf[tfidf_vector] for tfidf_vector in abstract_tokens_tfidf]\n",
    "vec_lda_bow = [lda_bow[bow_vector] for bow_vector in abstract_tokens_bow]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similarity matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsi_bow_index = similarities.MatrixSimilarity(lsi_bow[corpus])\n",
    "lsi_bow_index.save(\"models/indices/rationality_lsi_bow_mat_sim.index\")\n",
    "sims_lsi_bow = lsi_bow_index[vec_lsi_bow]\n",
    "\n",
    "lsi_tfidf_index = similarities.MatrixSimilarity(lsi_tfidf[corpus])\n",
    "lsi_tfidf_index.save(\"models/indices/rationality_lsi_tfidf_mat_sim.index\")\n",
    "sims_lsi_tfidf = lsi_tfidf_index[vec_lsi_tfidf]\n",
    "\n",
    "lda_bow_index = similarities.MatrixSimilarity(lda_bow[corpus])\n",
    "lda_bow_index.save(\"models/indices/rationality_lda_bow_mat_sim.index\")\n",
    "sims_lda_bow = lda_bow_index[vec_lda_bow]\n",
    "\n",
    "# Load index: index = similarities.MatrixSimilarity.load(\"/models/indices/rationality_lsi_bow_mat_sim.index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100.0</td>\n",
       "      <td>0.763705</td>\n",
       "      <td>0.187163</td>\n",
       "      <td>0.117203</td>\n",
       "      <td>0.630858</td>\n",
       "      <td>0.812657</td>\n",
       "      <td>0.917121</td>\n",
       "      <td>0.981435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100.0</td>\n",
       "      <td>0.679451</td>\n",
       "      <td>0.205645</td>\n",
       "      <td>0.169724</td>\n",
       "      <td>0.545178</td>\n",
       "      <td>0.695050</td>\n",
       "      <td>0.866757</td>\n",
       "      <td>0.991578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100.0</td>\n",
       "      <td>0.817545</td>\n",
       "      <td>0.119416</td>\n",
       "      <td>0.347124</td>\n",
       "      <td>0.750919</td>\n",
       "      <td>0.826029</td>\n",
       "      <td>0.911356</td>\n",
       "      <td>0.984627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100.0</td>\n",
       "      <td>0.727028</td>\n",
       "      <td>0.180020</td>\n",
       "      <td>0.111811</td>\n",
       "      <td>0.640128</td>\n",
       "      <td>0.753224</td>\n",
       "      <td>0.876731</td>\n",
       "      <td>0.971581</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   count      mean       std       min       25%       50%       75%       max\n",
       "0  100.0  0.763705  0.187163  0.117203  0.630858  0.812657  0.917121  0.981435\n",
       "1  100.0  0.679451  0.205645  0.169724  0.545178  0.695050  0.866757  0.991578\n",
       "2  100.0  0.817545  0.119416  0.347124  0.750919  0.826029  0.911356  0.984627\n",
       "3  100.0  0.727028  0.180020  0.111811  0.640128  0.753224  0.876731  0.971581"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TOP_N = 5\n",
    "\n",
    "sims_df = pd.DataFrame(sims_lsi_bow)\n",
    "sims_df.describe().transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### n-Docs most similar to corpus\n",
    "\n",
    "E.g. corpus represents your favourite docs and you search for n most similar docs from input docs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple heuristic, based on similarity average:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>a_mean</th>\n",
       "      <th>g_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.939831</td>\n",
       "      <td>0.966941</td>\n",
       "      <td>0.916430</td>\n",
       "      <td>0.926384</td>\n",
       "      <td>0.937397</td>\n",
       "      <td>0.937206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.922805</td>\n",
       "      <td>0.976067</td>\n",
       "      <td>0.922328</td>\n",
       "      <td>0.918191</td>\n",
       "      <td>0.934848</td>\n",
       "      <td>0.934549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.967506</td>\n",
       "      <td>0.931213</td>\n",
       "      <td>0.925871</td>\n",
       "      <td>0.912378</td>\n",
       "      <td>0.934242</td>\n",
       "      <td>0.934022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.962615</td>\n",
       "      <td>0.960259</td>\n",
       "      <td>0.915000</td>\n",
       "      <td>0.899151</td>\n",
       "      <td>0.934256</td>\n",
       "      <td>0.933843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.913568</td>\n",
       "      <td>0.919333</td>\n",
       "      <td>0.957195</td>\n",
       "      <td>0.939108</td>\n",
       "      <td>0.932301</td>\n",
       "      <td>0.932143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3    a_mean    g_mean\n",
       "7   0.939831  0.966941  0.916430  0.926384  0.937397  0.937206\n",
       "35  0.922805  0.976067  0.922328  0.918191  0.934848  0.934549\n",
       "8   0.967506  0.931213  0.925871  0.912378  0.934242  0.934022\n",
       "1   0.962615  0.960259  0.915000  0.899151  0.934256  0.933843\n",
       "23  0.913568  0.919333  0.957195  0.939108  0.932301  0.932143"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_sims_df = sims_df\n",
    "avg_sims_df[\"a_mean\"] = avg_sims_df.mean(axis=1)\n",
    "avg_sims_df[\"g_mean\"] = scipy.stats.mstats.gmean(avg_sims_df.iloc[:,:-1], axis=1) # more elaborated, cos skewed\n",
    "\n",
    "avg_sims_df_sorted = avg_sims_df.sort_values(by=\"g_mean\", ascending=False)\n",
    "avg_sims_df_sorted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similiar to corpus:\n",
      "\n",
      "\n",
      "Index of document: 7\n",
      "Document: Fashion-Gen: The Generative Fashion Dataset and Challenge by ['Negar Rostamzadeh', 'Seyedarian Hosseini', 'Thomas Boquet', 'Wojciech Stokowiec', 'Ying Zhang', 'Christian Jauvin', 'Chris Pal']\n",
      "\n",
      "Abstract: We introduce a new dataset of 293,008 high definition (1360 x 1360 pixels)\n",
      "fashion images paired with item descriptions provided by professional stylists.\n",
      "Each item is photographed from a variety of angles. We provide baseline results\n",
      "on 1) high-resolution image generation, and 2) image generation conditioned on\n",
      "the given text descriptions. We invite the community to improve upon these\n",
      "baselines. In this paper, we also outline the details of a challenge that we\n",
      "are launching based upon this dataset.\n",
      "\n",
      "\n",
      "\n",
      "Index of document: 35\n",
      "Document: DPP-Net: Device-aware Progressive Search for Pareto-optimal Neural\n",
      "  Architectures by ['Jin-Dong Dong', 'An-Chieh Cheng', 'Da-Cheng Juan', 'Wei Wei', 'Min Sun']\n",
      "\n",
      "Abstract: Recent breakthroughs in Neural Architectural Search (NAS) have achieved\n",
      "state-of-the-art performances in applications such as image classification and\n",
      "language modeling. However, these techniques typically ignore device-related\n",
      "objectives such as inference time, memory usage, and power consumption.\n",
      "Optimizing neural architecture for device-related objectives is immensely\n",
      "crucial for deploying deep networks on portable devices with limited computing\n",
      "resources. We propose DPP-Net: Device-aware Progressive Search for\n",
      "Pareto-optimal Neural Architectures, optimizing for both device-related (e.g.,\n",
      "inference time and memory usage) and device-agnostic (e.g., accuracy and model\n",
      "size) objectives. DPP-Net employs a compact search space inspired by current\n",
      "state-of-the-art mobile CNNs, and further improves search efficiency by\n",
      "adopting progressive search (Liu et al. 2017). Experimental results on CIFAR-10\n",
      "are poised to demonstrate the effectiveness of Pareto-optimal networks found by\n",
      "DPP-Net, for three different devices: (1) a workstation with Titan X GPU, (2)\n",
      "NVIDIA Jetson TX1 embedded system, and (3) mobile phone with ARM Cortex-A53.\n",
      "Compared to CondenseNet and NASNet-A (Mobile), DPP-Net achieves better\n",
      "performances: higher accuracy and shorter inference time on various devices.\n",
      "Additional experimental results show that models found by DPP-Net also achieve\n",
      "considerably-good performance on ImageNet as well.\n",
      "\n",
      "\n",
      "\n",
      "Index of document: 8\n",
      "Document: UnibucKernel Reloaded: First Place in Arabic Dialect Identification for\n",
      "  the Second Year in a Row by ['Andrei M. Butnaru', 'Radu Tudor Ionescu']\n",
      "\n",
      "Abstract: We present a machine learning approach that ranked on the first place in the\n",
      "Arabic Dialect Identification (ADI) Closed Shared Tasks of the 2018 VarDial\n",
      "Evaluation Campaign. The proposed approach combines several kernels using\n",
      "multiple kernel learning. While most of our kernels are based on character\n",
      "p-grams (also known as n-grams) extracted from speech or phonetic transcripts,\n",
      "we also use a kernel based on dialectal embeddings generated from audio\n",
      "recordings by the organizers. In the learning stage, we independently employ\n",
      "Kernel Discriminant Analysis (KDA) and Kernel Ridge Regression (KRR).\n",
      "Preliminary experiments indicate that KRR provides better classification\n",
      "results. Our approach is shallow and simple, but the empirical results obtained\n",
      "in the 2018 ADI Closed Shared Task prove that it achieves the best performance.\n",
      "Furthermore, our top macro-F1 score (58.92%) is significantly better than the\n",
      "second best score (57.59%) in the 2018 ADI Shared Task, according to the\n",
      "statistical significance test performed by the organizers. Nevertheless, we\n",
      "obtain even better post-competition results (a macro-F1 score of 62.28%) using\n",
      "the audio embeddings released by the organizers after the competition. With a\n",
      "very similar approach (that did not include phonetic features), we also ranked\n",
      "first in the ADI Closed Shared Tasks of the 2017 VarDial Evaluation Campaign,\n",
      "surpassing the second best method by 4.62%. We therefore conclude that our\n",
      "multiple kernel learning method is the best approach to date for Arabic dialect\n",
      "identification.\n",
      "\n",
      "\n",
      "\n",
      "Index of document: 1\n",
      "Document: Quantizing deep convolutional networks for efficient inference: A\n",
      "  whitepaper by ['Raghuraman Krishnamoorthi']\n",
      "\n",
      "Abstract: We present an overview of techniques for quantizing convolutional neural\n",
      "networks for inference with integer weights and activations. Per-channel\n",
      "quantization of weights and per-layer quantization of activations to 8-bits of\n",
      "precision post-training produces classification accuracies within 2% of\n",
      "floating point networks for a wide variety of CNN architectures. Model sizes\n",
      "can be reduced by a factor of 4 by quantizing weights to 8-bits, even when\n",
      "8-bit arithmetic is not supported. This can be achieved with simple, post\n",
      "training quantization of weights.We benchmark latencies of quantized networks\n",
      "on CPUs and DSPs and observe a speedup of 2x-3x for quantized implementations\n",
      "compared to floating point on CPUs. Speedups of up to 10x are observed on\n",
      "specialized processors with fixed point SIMD capabilities, like the Qualcomm\n",
      "QDSPs with HVX.\n",
      "  Quantization-aware training can provide further improvements, reducing the\n",
      "gap to floating point to 1% at 8-bit precision. Quantization-aware training\n",
      "also allows for reducing the precision of weights to four bits with accuracy\n",
      "losses ranging from 2% to 10%, with higher accuracy drop for smaller\n",
      "networks.We introduce tools in TensorFlow and TensorFlowLite for quantizing\n",
      "convolutional networks and review best practices for quantization-aware\n",
      "training to obtain high accuracy with quantized weights and activations. We\n",
      "recommend that per-channel quantization of weights and per-layer quantization\n",
      "of activations be the preferred quantization scheme for hardware acceleration\n",
      "and kernel optimization. We also propose that future processors and hardware\n",
      "accelerators for optimized inference support precisions of 4, 8 and 16 bits.\n",
      "\n",
      "\n",
      "\n",
      "Index of document: 23\n",
      "Document: Log Skeletons: A Classification Approach to Process Discovery by ['H. M. W. Verbeek', 'R. Medeiros de Carvalho']\n",
      "\n",
      "Abstract: To test the effectiveness of process discovery algorithms, a Process\n",
      "Discovery Contest (PDC) has been set up. This PDC uses a classification\n",
      "approach to measure this effectiveness: The better the discovered model can\n",
      "classify whether or not a new trace conforms to the event log, the better the\n",
      "discovery algorithm is supposed to be. Unfortunately, even the state-of-the-art\n",
      "fully-automated discovery algorithms score poorly on this classification. Even\n",
      "the best of these algorithms, the Inductive Miner, scored only 147 correct\n",
      "classified traces out of 200 traces on the PDC of 2017. This paper introduces\n",
      "the rule-based log skeleton model, which is closely related to the Declare\n",
      "constraint model, together with a way to classify traces using this model. This\n",
      "classification using log skeletons is shown to score better on the PDC of 2017\n",
      "than state-of-the-art discovery algorithms: 194 out of 200. As a result, one\n",
      "can argue that the fully-automated algorithm to construct (or: discover) a log\n",
      "skeleton from an event log outperforms existing state-of-the-art\n",
      "fully-automated discovery algorithms.\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Most similiar to corpus:\\n\\n\")\n",
    "\n",
    "for abstract_ix in avg_sims_df_sorted.index.values.tolist()[:TOP_N]:\n",
    "    print(\"Index of document:\", abstract_ix)\n",
    "    print(\"Document:\", titles[abstract_ix], \"by\", authors[abstract_ix])\n",
    "    print(\"\\nAbstract:\", abstracts[abstract_ix])\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### n-Docs most similar pairs\n",
    "\n",
    "E.g. corpus consist of all processed papers and you search for n most similar docs in corpus to input docs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32  1    0.991578\n",
       "53  2    0.984627\n",
       "86  0    0.981435\n",
       "25  1    0.979233\n",
       "43  0    0.978500\n",
       "dtype: float32"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_n_pairs = sims_df.stack().nlargest(TOP_N)\n",
    "top_n_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similiar pairs in descending order:\n",
      "\n",
      "\n",
      "Pair: 32 / 1\n",
      "Input document: Synaptic partner prediction from point annotations in insect brains by ['Julia Buhmann', 'Renate Krause', 'Rodrigo Ceballos Lentini', 'Nils Eckstein', 'Matthew Cook', 'Srinivas Turaga', 'Jan Funke']\n",
      "Corpus document: Rationalizing Neural Predictions\n",
      "\n",
      "Pair: 53 / 2\n",
      "Input document: Reservoir Computing Hardware with Cellular Automata by ['Alejandro Morán', 'Christiam F. Frasser', 'Josep L. Rosselló']\n",
      "Corpus document: Explaining the Predictions of Any Classifier\n",
      "\n",
      "Pair: 86 / 0\n",
      "Input document: Lifted Neural Networks by ['Armin Askari', 'Geoffrey Negiar', 'Rajiv Sambharya', 'Laurent El Ghaoui']\n",
      "Corpus document: Aspect-augmented Adversarial Networks for Domain Adaptation\n",
      "\n",
      "Pair: 25 / 1\n",
      "Input document: Emotional Conversation Generation Orientated Syntactically Constrained\n",
      "  Bidirectional-Asynchronous Framework by ['Xiao Sun', 'Jingyuan Li', 'Jianhua Tao']\n",
      "Corpus document: Rationalizing Neural Predictions\n",
      "\n",
      "Pair: 43 / 0\n",
      "Input document: Multi-Pointer Co-Attention Networks for Recommendation by ['Yi Tay', 'Luu Anh Tuan', 'Siu Cheung Hui']\n",
      "Corpus document: Aspect-augmented Adversarial Networks for Domain Adaptation\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Most similiar pairs in descending order:\\n\\n\")\n",
    "\n",
    "for abstract_ix, corpus_ix in zip(top_n_pairs.keys().labels[0], top_n_pairs.keys().labels[1]):\n",
    "    print(\"Pair:\", abstract_ix, \"/\", corpus_ix)\n",
    "    print(\"Input document:\", titles[abstract_ix], \"by\", authors[abstract_ix])\n",
    "    print(\"Corpus document:\", papers_titles[corpus_ix])\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
